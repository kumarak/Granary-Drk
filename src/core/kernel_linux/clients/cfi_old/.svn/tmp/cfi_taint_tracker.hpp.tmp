#ifndef CFI_TAINT_TRACKER_HPP_
#define CFI_TAINT_TRACKER_HPP_

#include <stdint.h>
#include <string.h>
#include <stddef.h>

#define U8(x) static_cast<uint8_t>(x)

#ifndef FORCE_INLINE
#   define FORCE_INLINE __attribute__((always_inline))
#endif

#if defined(__GNUC__) && !defined(__clang__)
#   define DECLTYPE decltype
#   define OFFSETOF __builtin_offsetof
#else
#   define DECLTYPE decltype
#   define OFFSETOF offsetof
#endif

/// forward declaration
void MurmurHash3_x86_32(const void *key, int len, uint32_t seed, void *out);

/// defines some tain meta information about a type
template <typename T>
struct taint_meta_info {
    enum {
        IS_TRACKED = 0,
        IS_STRUCT_TRACKED = 0,
    };
};

template <typename T>
struct taint_meta_info<const T> : public taint_meta_info<T> { };

/// extend the size of something to have enough space for a 32 bit hash
#define TAINT_SIZE_EXTENSION(rvalue) (4 + (4 - ((rvalue) % 4)))
#define TAINT_EXTEND_SIZE(lvalue) lvalue += TAINT_SIZE_EXTENSION(lvalue)

/// designate a function pointer field of a type to be the taint meta pointer
#define SET_TAINT_TRACKER(type, func_ptr_field_name) \
    template <> \
    struct taint_meta_info<type> { \
    public: \
        enum { \
            OFFSET = OFFSETOF(type, func_ptr_field_name), \
            IS_TRACKED = 1, \
            IS_STRUCT_TRACKED = 0, \
        }; \
    }

/// designate that a type is taint-tracked using structure extension
#define ADD_TAINT_TRACKER(type) \
    template <> \
    struct taint_meta_info<type> { \
    public: \
        enum { \
            OFFSET = sizeof(type) + TAINT_SIZE_EXTENSION(sizeof(type)) - 4U, \
            IS_TRACKED = 1, \
            IS_STRUCT_TRACKED = 1, \
        }; \
    }

/// simple interface to using function-tracked taineted data. Everything in body
/// is executed iff the data is tainted.
#define WITH_FUNC_TAINTED_DATA(rvalue, body) {\
    taint_tracked_data *tracker__(0); \
    typedef tracked_type<DECLTYPE(rvalue)> tracked_type__; \
    typedef typename tracked_type__::type tracked_base_type__; \
    typedef taint_meta_info<tracked_base_type__> tracked_type_meta__; \
    tracked_base_type__ *tracked_data__(tracked_type__::to_pointer(rvalue)); \
    bool tracker_is_new__(true); \
    bool tracker_is_dirty__(false); \
    if(taint_tracked_data::is_tracked(tracked_data__)) { \
        tracker_is_new__ = false; \
        tracker__ = taint_tracked_data::get_tracker(tracked_data__); \
        tracker_is_dirty__ = tracker__->is_dirty(); \
    } \
    if(tracker_is_new__ || tracker_is_dirty__) { \
        if(tracker_is_dirty__) { \
            tracker__->untrack<tracked_base_type__>(); \
        } \
        body \
        if(tracker_is_new__) { \
            taint_tracked_data::track(tracked_data__); \
        } else { \
            tracker__->update<tracked_base_type__>(); \
        } \
    }}

//#define IS_FIRST_TAINTING tracker_is_new__

/// simple interface to using structure-extneded taint tracking of data.
#define WITH_STRUCT_TAINTED_DATA(rvalue, body) {\
    typedef tracked_type<DECLTYPE(rvalue)> tracked_type__; \
    typedef typename tracked_type__::type tracked_base_type__; \
    typedef taint_meta_info<tracked_base_type__> tracked_type_meta__; \
    tracked_base_type__ *tracked_data__(tracked_type__::to_pointer(rvalue)); \
    uint32_t *taint_hash__ = (uint32_t *) &(((uint8_t *) tracked_data__)[tracked_type_meta__::OFFSET]); \
    uint32_t taint_new_hash__(0U); \
    MurmurHash3_x86_32(tracked_data__, sizeof(tracked_base_type__), taint_tracked_data::seed, &(taint_new_hash__)); \
    if(*taint_hash__ != taint_new_hash__) { \
        body \
    } \
    MurmurHash3_x86_32(tracked_data__, sizeof(tracked_base_type__), taint_tracked_data::seed, taint_hash__); \
    }


/// templates for removing pointers / references
template <typename T>
struct tracked_type {
public:
    typedef T type;
    FORCE_INLINE static T *to_pointer(T &val) throw() {
        return &val;
    }
};

template <typename T>
struct tracked_type<T &> {
public:
    typedef typename tracked_type<T>::type type;
    FORCE_INLINE static T *to_pointer(T &val) throw() {
        return tracked_type<T>::to_pointer(val);
    }
};

template <typename T>
struct tracked_type<T *> {
public:
    typedef typename tracked_type<T>::type type;
    FORCE_INLINE static T *to_pointer(T *val) throw() {
        return tracked_type<T>::to_pointer(*val);
    }
};

/// taint tracker struct. stores code and metadata about a structure being
/// tracked. takes up 20 bytes of memory, so not so bad ;-)
///
/// the designated function pointer of a taint-tracked structure can be
/// cast to a taint_tracker *, and then operated on like any C++ class
/// for maximum convenience.
struct taint_tracked_data {
public:

    enum {
        OP_JMP_NEAR_OFF32 = 0xE9,
        JMP_ADRR_LEN = 5 // 5 bytes to encode a jmp to a fixed address
    };

    /// global pointer to some dynamically allocated region for taint tracking
    /// metadata. When allocated, intialize next = begin, and initialize end
    /// to be just past the end of the array.
    static taint_tracked_data *begin;
    static taint_tracked_data *end;
    static taint_tracked_data *next;

    /// seed for the hash
    static uint32_t seed;

    /// just enough space to store a JMP operation
    uint8_t gencode[JMP_ADRR_LEN] __attribute__ ((aligned (8)));

    /// can we re-use this tracker?; eventually, we might want to create a
    /// kernel thread of our own that periodically scans the taint tracker
    /// shadow for "garbage". That is, suppose a tracked struct has its
    /// designated function pointer changed by the module. The next time
    /// we wrap that struct, we will allocate a new gencode for it, and
    /// it's previous one will be garbage. We can verify that it's
    /// garbage by using the tracked_struct_size and tracked_struct to
    /// re-inspect the struct and see if it's being tracked by another
    /// gencode thing, then mark this tracker as free and add it to a
    /// free list for future re-allocation.
    //bool is_free;
    bool is_free;

    /// needed for garbage collection; also helps fill up the empty space
    uint16_t tracked_struct_size;

    /// pointer back to the structure being tracked by the taint tracker.
    /// this is needed both for garbage collection, as well as de-allocation
    /// when trying to confirm that a de-allocator is indeed de-allocating
    /// a tracked structure.
    void *tracked_struct;

    /// murmurhash2, 32 bit hash of the structure being tracked
    uint32_t hash;

    /// notify the tracker to invalidate everything, i.e. change the seed
    static void invalidate(void) throw() {
        ++seed;
    }

    /// returns true iff the designated function pointer of some struct
    /// is currently tracked.
    template <typename T>
    FORCE_INLINE static bool is_tracked(T *struct_to_test) throw() {
        if(0 == struct_to_test) {
            return false;
        }
        return is_tracked(get_tracker(struct_to_test));
    }

    /// check if a pointer is tracked
    FORCE_INLINE static bool is_tracked(taint_tracked_data *tracker) throw() {
        if(begin <= tracker && tracker < next) { // it's in the "right" place
            return !(tracker->is_free); // it is potentially tracked
        }
        return false;
    }

    FORCE_INLINE static bool is_tracked(const taint_tracked_data *tracker) throw() {
        if(begin <= tracker && tracker < next) { // it's in the "right" place
            return !(tracker->is_free); // it is potentially tracked
        }
        return false;
    }

    /// check if a structure has been dirtied; we don't update the hash here
    /// as the structure needs to be re-wrapped after being dirtied
    bool is_dirty(void) const throw() {
        uint32_t curr_hash(0);
        MurmurHash3_x86_32(tracked_struct, tracked_struct_size, seed, &(curr_hash));
        return hash != curr_hash;
    }

    /// update the tracking hash
    template <typename T>
    void update(void) throw() {
        typedef taint_meta_info<T> meta_info;
        char *data((char *) tracked_struct);

        // a pointer to the structure's function pointer field, cast
        // as a pointer to a taint_tracked_data pointer
        taint_tracked_data **designated_ptr((taint_tracked_data **) &(data[meta_info::OFFSET]));

        // don't want a tracked function to be propagated
        if(is_tracked(*designated_ptr)) {
            *designated_ptr = (*designated_ptr)->get_target();
        }

        // initialize its gencode
        emit_jmp(&(gencode[0]), (void *) *designated_ptr);
        *designated_ptr = (taint_tracked_data *) &(gencode[0]);
        MurmurHash3_x86_32(tracked_struct, tracked_struct_size, seed, &(hash));
    }

    /// remove tracking pointer so that other stuff doesn't observe weird values
    template <typename T>
    void untrack(void) throw() {
        typedef taint_meta_info<typename tracked_type<T>::type> meta_info;
        uint8_t *data((uint8_t *) tracked_struct);
        *((taint_tracked_data **) &(data[meta_info::OFFSET])) = get_target();
    }

    template <typename T>
    FORCE_INLINE static taint_tracked_data *&get_tracker(T *struct_to_track) throw() {
        typedef taint_meta_info<T> meta_info;
        return *((taint_tracked_data **) &(((char *) struct_to_track)[meta_info::OFFSET]));
    }

    /// initialize a structure to be taint tracked. We assume that all functions
    /// have been wrapped (i.e. turned to shadow addresses if they were raw
    /// module addresses).
    ///
    /// the first argument is a pointer to the structure to be wrapped. this
    ///     structure must contain a function pointer.
    ///
    /// the second argument is a pointer to the function pointer that is the
    ///     designated tracking function pointer of the structure. if the structure
    ///     has multiple tracking pointers, then choose one and only one. be
    ///     consistent!
    template <typename T>
    static taint_tracked_data *track(T *struct_to_init) throw() {
        typedef taint_meta_info<T> meta_info;

        taint_tracked_data *tracker = allocate_tracker();

        // replace the function pointer with a pointer to the gencode,
        // initialize the rest of the tracker, then hash the structure
        // with the gencode pointer
        tracker->is_free = false;
        tracker->tracked_struct_size = (uint16_t) sizeof(T);
        tracker->tracked_struct = struct_to_init;
        tracker->update<T>();

        return (taint_tracked_data *) tracker->gencode;
    }

    /// get the untracked version of a pointer (the target of the JMP), still
    /// left as the tracked type for simplicity
    taint_tracked_data *get_target(void) const throw() {
        uint64_t offset(gencode[4]);
        offset = (offset << 8) | gencode[3];
        offset = (offset << 8) | gencode[2];
        offset = (offset << 8) | gencode[1];
        offset += ((uint64_t) gencode) + 5ULL;
        return (taint_tracked_data *) offset;
    }

private:

    /// allocate a new tracker
    static taint_tracked_data *allocate_tracker(void) throw() {
        taint_tracked_data *mine(0);
        __asm__ __volatile__ (
            "push %%rax;"
            "push %%rdx;"
        "1:"
            "mov %1, %%rax;"            // %rax = next
            "mov %%rax, %0;"            // mine = next
            "mov %%rax, %%rdx;"         // %rdx = next + 1
            "add $20, %%rdx;"           // 20 == sizeof(taint_tracked_data)

            "lock;"                     // make the CAS atomic
            "cmpxchg %%rdx, %1;"        // if next == %rax
                                        //    then next = %rdx, ZF = 1
                                        //    else %rax = next + 1, ZF = 0
            "jnz 1b;"    // if ZF == 0 then goto find_next_tracked;

            "pop %%rdx;"
            "pop %%rax;"

            : "=r"(mine)
            : "m"(taint_tracked_data::next)

            // clobbered
            : "rax", "rdx"
        );

        return mine;
    }

    /// patch a block of code to jump to a specific address.
    static void emit_jmp(uint8_t *begin, void *func) throw() {
        const ptrdiff_t offset(((ptrdiff_t) func) - (((ptrdiff_t) begin) + 5));

        const uint8_t CALL_FUNC_OP[] = {
            OP_JMP_NEAR_OFF32,
            U8((offset >>  0) & 0xFF),
            U8((offset >>  8) & 0xFF),
            U8((offset >> 16) & 0xFF),
            U8((offset >> 24) & 0xFF)
        };

        memcpy(begin, CALL_FUNC_OP, sizeof CALL_FUNC_OP);
    }

} __attribute__((packed));

/// initialize the static data
taint_tracked_data *taint_tracked_data::begin((taint_tracked_data *)MODULE_SHADOW_END);
taint_tracked_data *taint_tracked_data::end((taint_tracked_data *)MODULE_SHADOW_END_EXTENDED);
taint_tracked_data *taint_tracked_data::next((taint_tracked_data *)MODULE_SHADOW_END);
uint32_t taint_tracked_data::seed = 0xdeadbeef;


extern "C" {
    void *cfi_get_untracked_address(void *addr_) {
        const taint_tracked_data *tracker = (taint_tracked_data *) addr_;
        if(taint_tracked_data::is_tracked(tracker)) {
            return (void *) tracker->get_target();
        } else {
            return addr_;
        }
    }
}

//-----------------------------------------------------------------------------
// MurmurHash3 was written by Austin Appleby, and is placed in the public
// domain. The author hereby disclaims copyright to this source code.

// Note - The x86 and x64 versions do _not_ produce the same results, as the
// algorithms are optimized for their respective platforms. You can still
// compile and run any of them on any platform, but your performance with the
// non-native version will be less than optimal.


inline uint32_t rotl32 ( uint32_t x, int8_t r )
{
  return (x << r) | (x >> (32 - r));
}

inline uint64_t rotl64 ( uint64_t x, int8_t r )
{
  return (x << r) | (x >> (64 - r));
}

#define ROTL32(x,y) rotl32(x,y)
#define ROTL64(x,y) rotl64(x,y)

#define BIG_CONSTANT(x) (x##LLU)

//-----------------------------------------------------------------------------
// Block read - if your platform needs to do endian-swapping or can only
// handle aligned reads, do the conversion here

FORCE_INLINE uint32_t getblock ( const uint32_t * p, int i )
{
  return p[i];
}

FORCE_INLINE uint64_t getblock ( const uint64_t * p, int i )
{
  return p[i];
}

//-----------------------------------------------------------------------------
// Finalization mix - force all bits of a hash block to avalanche

FORCE_INLINE uint32_t fmix ( uint32_t h )
{
  h ^= h >> 16;
  h *= 0x85ebca6b;
  h ^= h >> 13;
  h *= 0xc2b2ae35;
  h ^= h >> 16;

  return h;
}

//----------

FORCE_INLINE uint64_t fmix ( uint64_t k )
{
  k ^= k >> 33;
  k *= BIG_CONSTANT(0xff51afd7ed558ccd);
  k ^= k >> 33;
  k *= BIG_CONSTANT(0xc4ceb9fe1a85ec53);
  k ^= k >> 33;

  return k;
}

//-----------------------------------------------------------------------------

FORCE_INLINE void MurmurHash3_x86_32 ( const void * key, int len,
                          uint32_t seed, void * out )
{
  const uint8_t * data = (const uint8_t*)key;
  const int nblocks = len / 4;

  uint32_t h1 = seed;

  const uint32_t c1 = 0xcc9e2d51;
  const uint32_t c2 = 0x1b873593;

  //----------
  // body

  const uint32_t * blocks = (const uint32_t *)(data + nblocks*4);

  for(int i = -nblocks; i; i++)
  {
    uint32_t k1 = getblock(blocks,i);

    k1 *= c1;
    k1 = ROTL32(k1,15);
    k1 *= c2;

    h1 ^= k1;
    h1 = ROTL32(h1,13);
    h1 = h1*5+0xe6546b64;
  }

  //----------
  // tail

  const uint8_t * tail = (const uint8_t*)(data + nblocks*4);

  uint32_t k1 = 0;

  switch(len & 3)
  {
  case 3: k1 ^= tail[2] << 16;
  case 2: k1 ^= tail[1] << 8;
  case 1: k1 ^= tail[0];
          k1 *= c1; k1 = ROTL32(k1,15); k1 *= c2; h1 ^= k1;
  };

  //----------
  // finalization

  h1 ^= len;

  h1 = fmix(h1);

  *(uint32_t*)out = h1;
}

//-----------------------------------------------------------------------------
#endif
